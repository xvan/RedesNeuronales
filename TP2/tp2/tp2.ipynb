{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # To use the venv as jupyter kernel\n",
    " # python -m ipykernel install --user --name tp2 --display-name \"Python (tp2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "\n",
    "import mpl_toolkits.mplot3d.proj3d\n",
    "\n",
    "sys.path.append('src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tp2\n",
    "from tp2.perceptron import ThresholdUnit, NonLinearUnit\n",
    "from tp2.multilayer import MultilayerNetwork, BackPropagationMultistartTrainer\n",
    "from tp2.multilayer import SimulatedAnnealingTrainer\n",
    "import tp2.aux as tp2Aux\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(tp2.perceptron)\n",
    "importlib.reload(tp2.multilayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(tp2Aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Implemente un perceptrón simple que aprenda la función lógica AND de 2 y de 4 entradas. Lo mismo para la función lógica OR. Para el caso de 2 dimensiones, grafique la recta discriminadora y todos los vectores de entrada de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### AND de dos entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tabla de entradas / salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "and_truth_table = [\n",
    "        ((1, 1), [1]),\n",
    "        ((1, -1), [-1]),\n",
    "        ((-1, 1), [-1]),\n",
    "        ((-1, -1), [-1])\n",
    "    ]\n",
    "\n",
    "tp2Aux.train_data_to_df(and_truth_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pesos tras el entrenamiento. El 0 corresponde al bias, modelado como una entrada constante $x_0 = -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tu_and=ThresholdUnit()\n",
    "tu_and.train(and_truth_table)\n",
    "tp2Aux.weights_to_df(tu_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La ecuación de la recta de decisión es $-w_0 + x_1 w_1 + x2_2 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tp2Aux.plot_2d_tu(tu_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### OR de dos entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tabla de entradas / salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "or_truth_table = [\n",
    "        ((1, 1), [1]),\n",
    "        ((1, -1), [1]),\n",
    "        ((-1, 1), [1]),\n",
    "        ((-1, -1), [-1])\n",
    "    ]\n",
    "\n",
    "tp2Aux.train_data_to_df(or_truth_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pesos tras el entrenamiento. El 0 corresponde al bias, modelado como una entrada constante $x_0 = -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tu_or=ThresholdUnit()\n",
    "tu_or.train(or_truth_table)\n",
    "tp2Aux.weights_to_df(tu_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tp2Aux.plot_2d_tu(tu_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### AND de 4 entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tabla de entradas / salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "and4_truth_table = [\n",
    "    (( 1,  1,  1,  1), [ 1]),\n",
    "    (( 1,  1,  1, -1), [-1]),\n",
    "    (( 1,  1, -1,  1), [-1]),\n",
    "    (( 1,  1, -1, -1), [-1]),\n",
    "    (( 1, -1,  1,  1), [-1]),\n",
    "    (( 1, -1,  1, -1), [-1]),\n",
    "    (( 1, -1, -1,  1), [-1]),\n",
    "    (( 1, -1, -1, -1), [-1]),\n",
    "    ((-1,  1,  1,  1), [-1]),\n",
    "    ((-1,  1,  1, -1), [-1]),\n",
    "    ((-1,  1, -1,  1), [-1]),\n",
    "    ((-1,  1, -1, -1), [-1]),\n",
    "    ((-1, -1,  1,  1), [-1]),\n",
    "    ((-1, -1,  1, -1), [-1]),\n",
    "    ((-1, -1, -1,  1), [-1]),\n",
    "    ((-1, -1, -1, -1), [-1]),\n",
    "        \n",
    "    ]\n",
    "\n",
    "tp2Aux.train_data_to_df(and4_truth_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pesos tras el entrenamiento. El 0 corresponde al bias, modelado como una entrada constante $x_0 = -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tu_and4=ThresholdUnit()\n",
    "tu_and4.train(and4_truth_table)\n",
    "tp2Aux.weights_to_df(tu_and4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### OR de 4 entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "or4_truth_table = [\n",
    "    (( 1,  1,  1,  1), [ 1]),\n",
    "    (( 1,  1,  1, -1), [ 1]),\n",
    "    (( 1,  1, -1,  1), [ 1]),\n",
    "    (( 1,  1, -1, -1), [ 1]),\n",
    "    (( 1, -1,  1,  1), [ 1]),\n",
    "    (( 1, -1,  1, -1), [ 1]),\n",
    "    (( 1, -1, -1,  1), [ 1]),\n",
    "    (( 1, -1, -1, -1), [ 1]),\n",
    "    ((-1,  1,  1,  1), [ 1]),\n",
    "    ((-1,  1,  1, -1), [ 1]),\n",
    "    ((-1,  1, -1,  1), [ 1]),\n",
    "    ((-1,  1, -1, -1), [ 1]),\n",
    "    ((-1, -1,  1,  1), [ 1]),\n",
    "    ((-1, -1,  1, -1), [ 1]),\n",
    "    ((-1, -1, -1,  1), [ 1]),\n",
    "    ((-1, -1, -1, -1), [-1]),\n",
    "    ]\n",
    "\n",
    "tp2Aux.train_data_to_df(or4_truth_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tu_or4=ThresholdUnit()\n",
    "tu_or4.train(or4_truth_table)\n",
    "tp2Aux.weights_to_df(tu_or4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Determine numéricamente cómo varia la capacidad del perceptrón simple en función del número de patrones enseñados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se configuró una Threshold Unit (perceptron que utiliza la función signo) con $N = [1 .. 10]$ entradas.\n",
    "\n",
    "Para cada configuración, y se entrena con K pares de entrada/salida  $(\\mathbf{x}, y )$ aleatorios.\n",
    "\n",
    "$\\mathbf{x}$ es un vector de $N$ entradas aleatorias de distribución $U_{-1,1}$, $y$ una Bernoulli ${[-1,1]}$ con $P(\\frac{1}{2})$\n",
    "\n",
    "Mediante método de Montecarlo se estima la tasa de éxito de un entrenamiento de $K$ muestras aleatorias en un perceptrón de $N$ entradas, comenzando con $K=1$. El experimento se repite hasta obtener estimadores de la tasa de éxito con un error de $\\pm 0.02$ en un intervalo de confianza del $95\\%$\n",
    "\n",
    "Para el caso de $N=1$ el método se validó contra el análisis analítico de la tasa de éxito. Se encontró que para 1000 de iteraciones y velocidad de convergencia $\\eta=0.01$ seleccionados, el entrenamiento no encontraba solución a casos linealmente separables. Aún así se determinó que esos errores no modificaban considerablemente la salida del Montecarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfCap=pd.read_csv(\"data/capacity.csv\", usecols= lambda x: x in [\"dim\", \"pmax\", \"cap\"]).sort_values([\"dim\", \"pmax\"])\n",
    "\n",
    "for dim,dim_cap in dfCap.groupby(\"dim\"):\n",
    "    plt.plot( dim_cap[\"pmax\"]/dim_cap[\"dim\"], dim_cap[\"cap\"], label=int(dim))\n",
    "\n",
    "plt.xlabel(\"pmax/N\")\n",
    "plt.ylabel(\"capacity\")\n",
    "plt.legend(title=\"N\")\n",
    "plt.title(\"Capacidad de una Threshold Unit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se observa que el ThresholdUnit tiene capacidad cercana a 1 para $\\frac{\\mathrm{pmax}}{N} \\lt 1.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. a) Implemente un perceptrón multicapa que aprenda la función lógica XOR de 2 y de 4 entradas (utilizando el algoritmo Backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se comienza reimplementando el perceptrón simple utilizando Non Linear Units con $tanh$ como función de activación.\n",
    "Se optimizan los pesos aplicando gradiente descendente sobre la función consto $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$C = \\sum_k ( \\zeta_k - g(\\mathbf{w}^\\mathrm{T} \\cdot \\mathbf{x_k}) )^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$\\nabla C = \\sum_k 2 ( \\zeta_k - g(\\mathbf{w}^\\mathrm{T} \\cdot \\mathbf{x_k}))  g'(\\mathbf{w}^\\mathrm{T} \\cdot \\mathbf{x_k}) \\mathbf{x_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se ensaya el correcto funcionamiento de la Non Linear Unit aprendiendo la función OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlu_or=NonLinearUnit()\n",
    "nlu_or.train(or_truth_table)\n",
    "tp2Aux.train_data_to_df([ (x,nlu_or.process(x)) for x,y in or_truth_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se implementa una red multi capa en base a las non linear units. Los pesos se inicializan de manera aleatoria y se optimizan mediante gradiente descendiente y back-propagation. El algoritmo se detiene cuando no detecta mejoras significativas en la función costo.\n",
    "En caso de converger a un mínimo local, se reinicializa el algoritmo en otro punto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Función XOR de 2 compuertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xor_gate_table = [\n",
    "    ((1, 1), (-1,)),\n",
    "    ((1, -1), (1,)),\n",
    "    ((-1, 1), (1,)),\n",
    "    ((-1, -1), (-1,))\n",
    "]\n",
    "\n",
    "tp2Aux.train_data_to_df(xor_gate_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mn_xor2=MultilayerNetwork([2,2,1])\n",
    "trainer_xor2 = BackPropagationMultistartTrainer(mn_xor2,xor_gate_table,1)\n",
    "xor2_costs=[]\n",
    "trainer_xor2.cost_callback = lambda x: xor2_costs.append(x)\n",
    "trainer_xor2.train()\n",
    "tp2Aux.train_data_to_df([ (x,mn_xor2.process(x)) for x,y in xor_gate_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Función XOR de 4 compuertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "large_xor_gate_table = [\n",
    "    (( 1,  1,  1,  1), (-1,)),\n",
    "    (( 1,  1,  1, -1), (-1,)),\n",
    "    (( 1,  1, -1,  1), (-1,)),\n",
    "    (( 1,  1, -1, -1), (-1,)),\n",
    "    (( 1, -1,  1,  1), (-1,)),\n",
    "    (( 1, -1,  1, -1), (-1,)),\n",
    "    (( 1, -1, -1,  1), (-1,)),\n",
    "    (( 1, -1, -1, -1), ( 1,)),\n",
    "    ((-1,  1,  1,  1), (-1,)),\n",
    "    ((-1,  1,  1, -1), (-1,)),\n",
    "    ((-1,  1, -1,  1), (-1,)),\n",
    "    ((-1,  1, -1, -1), ( 1,)),\n",
    "    ((-1, -1,  1,  1), (-1,)),\n",
    "    ((-1, -1,  1, -1), ( 1,)),\n",
    "    ((-1, -1, -1,  1), ( 1,)),\n",
    "    ((-1, -1, -1, -1), (-1,)),\n",
    "]\n",
    "\n",
    "tp2Aux.train_data_to_df(large_xor_gate_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn_xor4=MultilayerNetwork([4,2,1])\n",
    "trainer_xor4 = BackPropagationMultistartTrainer(nn_xor4,large_xor_gate_table,1)\n",
    "xor4_costs=[]\n",
    "trainer_xor4.cost_callback = lambda x: xor4_costs.append(x)\n",
    "trainer_xor4.train()\n",
    "tp2Aux.train_data_to_df([ (x,nn_xor4.process(x)) for x,y in large_xor_gate_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. b) Muestre cómo evoluciona el error durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xor2_costs)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.title(\"2 gates xor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xor4_costs)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.title(\"4 gates xor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "En la evolución del costo para la xor de 4 entradas se observa que el costo se estanca en mínimos locales y es necesario reiniciar el algoritmo.\n",
    "La búsqueda del mínimo se facilita si se expande de 2 a 5 neuronas la capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('default', category=np.VisibleDeprecationWarning)\n",
    "mn_xor4_h5=MultilayerNetwork([4,5,1])\n",
    "trainer_xor4_h5 = BackPropagationMultistartTrainer(mn_xor4_h5,large_xor_gate_table,1)\n",
    "trainer_xor4_h5.learning_rate=0.001\n",
    "xor4_costs_h5=[]\n",
    "trainer_xor4_h5.cost_callback = lambda x: xor4_costs_h5.append(x)\n",
    "trainer_xor4_h5.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xor4_costs_h5)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.title(\"4 gates xor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. c) Para una red entrenada en la función XOR de dos entradas, grafique el error en función de dos pesos cualesquiera de la red. De ejemplos de mínimos locales y mesetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se plotean las curvas de nivel para todos los pares de pesos posibles.\n",
    "Las coordenadas de los pesos se leen de la siguiente forma. Una coordenada $(a,(b,c))$, representa el peso en el layer $a$, desde la entrada $V_b$ a la neurona $c$.\n",
    "La entrada $b=0$ corresponde al bias modelado como una entrada constante $v_0=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(tp2Aux)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "tp2Aux.plot_all_cuts(trainer_xor2,xor_gate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "En los cortes inspeccionados no se detectaron algunos mínimos locales. Por ejemplo en el gráfico de la coordenada (0,(1,1)) vs (1,(2,0)) hay un mínimo entre las curvas de nivel de 1.5 y 3.  Esto coincide con los mínimos locales de costo alrededor de 1.7 en los que a veces se estanca el optimizador.\n",
    "\n",
    "En los cortes donde las curvas de nivel corren verticalmente, puede asociarse a mesetas. Por ejemplo el gráfico de la coordenada (0,(0,0)) vs (0,(1,0)), pueden observarse mesetas en 8 y en 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. d) Idem (c) pero computando el error para cada patrón de entrada por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(tp2Aux)\n",
    "plt.rcParams['figure.figsize'] = (25.0, 5.0)\n",
    "tp2Aux.plot_all_cuts_per_sample(trainer_xor2,xor_gate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "En los gráficos individuales se observa que hay pesos que se afectan el costo de solo parte de las entradas.\n",
    "También se aprecia como la composición final del costo está determinada por la suma de los costos de las entradas individuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. a) Implemente una red con aprendizaje Backpropagation que aprenda la siguiente función $f(x, y, z) = \\sin(x) + \\cos(y) + z$ donde: $x, y \\in [0, 2\\pi]$ y $z \\in [−1,1]$. Para ello construya un conjunto de datos de entrenamiento y un conjunto de evaluación. Muestre el error en función de las épocas de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def cleanLastPrintedLine():\n",
    "#     print(\" \" * 100, end='\\r')\n",
    "#\n",
    "# def func_logging(func_costs, cost):\n",
    "#     cleanLastPrintedLine()\n",
    "#     print(cost, end='\\r')\n",
    "#     func_costs.append(cost)\n",
    "#\n",
    "# training_samples, testing_samples = tp2Aux.Exercise4.generate_dataset(20, 0.8)\n",
    "# layers = [3, 25, 1]\n",
    "# func_costs = []\n",
    "# mn = MultilayerNetwork(layers)\n",
    "# mn.perceptrons[-1].activator = lambda x: x\n",
    "# trainer = SingleAttemptMultilayerTrainer(mn, training_samples, 1)\n",
    "# trainer.cost_callback = lambda x: func_logging(func_costs, x)\n",
    "# trainer.learning_rate = 0.01\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/minibatch.pkl\",\"rb\") as fi:\n",
    "    sim_data = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for data in sim_data:\n",
    "    error = [pair[0] for pair in data[3]]\n",
    "    plt.plot(error, label = \"(%i, %0.3f)\" % data[:2])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cost\")\n",
    "#plt.legend(title = \"minibatch, learning rate\")\n",
    "plt.title(\"sin(x)+cos(y)+z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se realizó un barrido de 1000 epochs con learning rates entre 0.1 y 0.001, y distintos tamaños de minibatch. Se observa que la mayoría de las configuraciones no minimizan la función costo a valores interesantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_data = [data for data in sim_data if data[3][-1][0] < 0.4]\n",
    "for data in filtered_data:\n",
    "    error = [pair[0] for pair in data[3]]\n",
    "    plt.plot(error, label = \"(%i, %0.3f)\" % data[:2])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.legend(title = \"minibatch, learning rate\")\n",
    "plt.title(\"sin(x)+cos(y)+z\")\n",
    "filtered_data = sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_data = [data for data in sim_data if data[3][-1][0] < 0.1]\n",
    "for data in filtered_data:\n",
    "    error = [pair[0] for pair in data[3]]\n",
    "    plt.plot(error, label = \"(%i, %0.3f)\" % data[:2])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.legend(title = \"minibatch, learning rate\")\n",
    "plt.title(\"sin(x)+cos(y)+z\")\n",
    "filtered_data = sim_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sim_data[0][3][-1][0] < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## 6 Encontrar un perceptrón multicapa que resuelva una XOR de 2 entradas mediantesimulated annealing. Graficar el error a lo largo del proceso de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layers = [2, 2, 1]\n",
    "mn = MultilayerNetwork(layers)\n",
    "annealing_trainer = SimulatedAnnealingTrainer(mn, xor_gate_table)\n",
    "annealing_costs=[]\n",
    "annealing_trainer.temperature_callback = lambda t,c: annealing_costs.append([t,c])\n",
    "annealing_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "annealing_array=np.array(annealing_costs)\n",
    "plt.plot(annealing_array[:,0],annealing_array[:,1])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"temperature\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "plt.title(\"2 Gates XOR with simmulated annealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layers = [2, 2, 1]\n",
    "mn = MultilayerNetwork(layers)\n",
    "annealing_trainer = SimulatedAnnealingMultilayerTrainer(mn, xor_gate_table)\n",
    "annealing_costs=[]\n",
    "annealing_trainer.temperature_callback = lambda t,c: annealing_costs.append([t,c])\n",
    "annealing_trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annealing_array=np.array(annealing_costs)\n",
    "plt.plot(annealing_array[:,0],annealing_array[:,1])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"temperature\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "plt.title(\"2 Gates XOR with simmulated annealing\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [2, 2, 1]\n",
    "mn = MultilayerNetwork(layers)\n",
    "annealing_trainer = SimulatedAnnealingMultilayerTrainer(mn, xor_gate_table)\n",
    "annealing_costs=[]\n",
    "annealing_trainer.temperature_callback = lambda t,c: annealing_costs.append([t,c])\n",
    "annealing_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealing_array=np.array(annealing_costs)\n",
    "plt.plot(annealing_array[:,0],annealing_array[:,1])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"temperature\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "plt.title(\"2 Gates XOR with simmulated annealing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}